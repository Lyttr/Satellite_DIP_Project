{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkTByfMhTEq5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import models\n",
        "\n",
        "def build_resnet18(\n",
        "    num_classes: int,\n",
        "    pretrained: bool = True,\n",
        "    dropout: float = 0.0,\n",
        "    freeze_backbone: bool = False,\n",
        "    in_channels: int = 3,\n",
        ") -> nn.Module:\n",
        "\n",
        "    try:\n",
        "        weights = models.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None\n",
        "        model = models.resnet18(weights=weights)\n",
        "    except Exception:\n",
        "        model = models.resnet18(pretrained=pretrained)\n",
        "\n",
        "    if in_channels != 3:\n",
        "        model.conv1 = nn.Conv2d(in_channels, model.conv1.out_channels,\n",
        "                                kernel_size=model.conv1.kernel_size,\n",
        "                                stride=model.conv1.stride,\n",
        "                                padding=model.conv1.padding,\n",
        "                                bias=False)\n",
        "\n",
        "    if freeze_backbone:\n",
        "        for name, p in model.named_parameters():\n",
        "            if not name.startswith(\"fc.\"):\n",
        "                p.requires_grad = False\n",
        "\n",
        "    in_feats = model.fc.in_features\n",
        "    if dropout and dropout > 0.0:\n",
        "        model.fc = nn.Sequential(\n",
        "            nn.Dropout(p=dropout),\n",
        "            nn.Linear(in_feats, num_classes),\n",
        "        )\n",
        "    else:\n",
        "        model.fc = nn.Linear(in_feats, num_classes)\n",
        "\n",
        "    head = model.fc[-1] if isinstance(model.fc, nn.Sequential) else model.fc\n",
        "    nn.init.kaiming_uniform_(head.weight, nonlinearity='relu')\n",
        "    nn.init.zeros_(head.bias)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "def save_checkpoint(model: nn.Module, path: str):\n",
        "    torch.save(model.state_dict(), path)\n",
        "\n",
        "\n",
        "def load_checkpoint(model: nn.Module, path: str, map_location='cpu', strict=True, expected_in_channels: int = 3):\n",
        "    state = torch.load(path, map_location=map_location)\n",
        "\n",
        "    model_conv1_in_channels = model.conv1.in_channels\n",
        "\n",
        "    if 'conv1.weight' in state:\n",
        "        checkpoint_conv1_in_channels = state['conv1.weight'].shape[1]\n",
        "\n",
        "        if model_conv1_in_channels != checkpoint_conv1_in_channels:\n",
        "            print(f\"Warning: Model expects {model_conv1_in_channels} channels for conv1, but checkpoint has {checkpoint_conv1_in_channels}. Skipping loading conv1.weight.\")\n",
        "            del state['conv1.weight']\n",
        "            strict = False\n",
        "\n",
        "    model.load_state_dict(state, strict=strict)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ce_rDVhRTY7H"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "\n",
        "def homomorphic_filter_rgb(img_pil, sigma=30.0, gamma_l=0.7, gamma_h=1.5, eps=1e-6):\n",
        "    img = np.array(img_pil.convert(\"RGB\"), dtype=np.uint8)\n",
        "    ycrcb = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb).astype(np.float32)\n",
        "    luminance = ycrcb[..., 0] / 255.0\n",
        "    log_y = np.log1p(luminance + eps)\n",
        "    freq = np.fft.fftshift(np.fft.fft2(log_y))\n",
        "    rows, cols = luminance.shape\n",
        "    u = np.arange(rows) - rows / 2.0\n",
        "    v = np.arange(cols) - cols / 2.0\n",
        "    vv, uu = np.meshgrid(v, u)\n",
        "    distance = np.sqrt(uu ** 2 + vv ** 2)\n",
        "    high_pass = (gamma_h - gamma_l) * (1.0 - np.exp(-(distance ** 2) / (2.0 * (sigma ** 2)))) + gamma_l\n",
        "    filtered = np.real(np.fft.ifft2(np.fft.ifftshift(freq * high_pass)))\n",
        "    exp_y = np.expm1(filtered)\n",
        "    exp_y = np.clip(exp_y, 0.0, None)\n",
        "    normalized = cv2.normalize(exp_y.astype(np.float32), None, 0.0, 1.0, cv2.NORM_MINMAX)\n",
        "    ycrcb[..., 0] = np.clip(normalized * 255.0, 0.0, 255.0)\n",
        "    out = cv2.cvtColor(ycrcb.astype(np.uint8), cv2.COLOR_YCrCb2RGB)\n",
        "    return Image.fromarray(out)\n",
        "\n",
        "def logarithmic_enhancement_rgb(img_pil, c=1.0):\n",
        "    img = np.array(img_pil.convert(\"RGB\"), dtype=np.float32) / 255.0\n",
        "    enhanced = c * np.log1p(img) / np.log1p(1.0)\n",
        "    enhanced = np.clip(enhanced, 0.0, 1.0)\n",
        "    enhanced = (enhanced * 255.0).astype(np.uint8)\n",
        "    return Image.fromarray(enhanced)\n",
        "\n",
        "def extract_frequency_features(img_pil):\n",
        "    img = np.array(img_pil.convert(\"L\"), dtype=np.float32) # Convert to grayscale\n",
        "    f = np.fft.fft2(img)\n",
        "    fshift = np.fft.fftshift(f)\n",
        "    magnitude_spectrum = 20 * np.log(np.abs(fshift) + 1) # Logarithmic magnitude spectrum\n",
        "    return magnitude_spectrum\n",
        "\n",
        "\n",
        "class CombinedEnhancementAndFreq(object):\n",
        "    \"\"\"Custom transform to apply enhancement and add frequency features as a channel.\"\"\"\n",
        "    def __init__(self, homo_params=None, log_params=None):\n",
        "        self.homo_params = homo_params or {}\n",
        "        self.log_params = log_params or {}\n",
        "\n",
        "    def __call__(self, img_pil):\n",
        "        homo_img_pil = homomorphic_filter_rgb(img_pil, **self.homo_params)\n",
        "\n",
        "        log_img_pil = logarithmic_enhancement_rgb(homo_img_pil, **self.log_params)\n",
        "\n",
        "        transform_to_tensor = transforms.ToTensor()\n",
        "        rgb_tensor = transform_to_tensor(log_img_pil) # (3, H, W)\n",
        "\n",
        "        freq_magnitude = extract_frequency_features(img_pil)\n",
        "\n",
        "        freq_magnitude_norm = (freq_magnitude - freq_magnitude.min()) / (freq_magnitude.max() - freq_magnitude.min() + 1e-6)\n",
        "        freq_pil = Image.fromarray((freq_magnitude_norm * 255).astype(np.uint8))\n",
        "\n",
        "        freq_pil = transforms.Resize(img_pil.size)(freq_pil)\n",
        "        freq_tensor = transform_to_tensor(freq_pil).squeeze(0) # (1, H, W) after squeeze(0)\n",
        "        if freq_tensor.dim() == 2:\n",
        "            freq_tensor = freq_tensor.unsqueeze(0) # Make it (1, H, W)\n",
        "\n",
        "        if rgb_tensor.shape[1:] != freq_tensor.shape[1:]:\n",
        "            raise ValueError(f\"Shape mismatch in CombinedEnhancementAndFreq: RGB {rgb_tensor.shape[1:]} vs Freq {freq_tensor.shape[1:]}\")\n",
        "\n",
        "        combined_tensor = torch.cat((rgb_tensor, freq_tensor), dim=0) # (4, H, W)\n",
        "        return combined_tensor\n",
        "\n",
        "\n",
        "def build_eval_transform(\n",
        "    img_size,\n",
        "    enhancement=\"homomorphic\",\n",
        "    homo_params=None,\n",
        "    log_params=None,\n",
        "    in_channels: int = 3,\n",
        "):\n",
        "    homo_params = homo_params or {}\n",
        "    log_params = log_params or {}\n",
        "    steps = [transforms.Resize((img_size, img_size))]\n",
        "    if enhancement == \"homomorphic\":\n",
        "        steps.append(transforms.Lambda(lambda im: homomorphic_filter_rgb(im, **homo_params)))\n",
        "        steps.append(transforms.ToTensor())\n",
        "    elif enhancement == \"log\":\n",
        "        steps.append(transforms.Lambda(lambda im: logarithmic_enhancement_rgb(im, **log_params)))\n",
        "        steps.append(transforms.ToTensor())\n",
        "    elif enhancement == \"homo+log\":\n",
        "        steps.append(transforms.Lambda(lambda im: homomorphic_filter_rgb(im, **homo_params)))\n",
        "        steps.append(transforms.Lambda(lambda im: logarithmic_enhancement_rgb(im, **log_params)))\n",
        "        steps.append(transforms.ToTensor())\n",
        "    elif enhancement == \"combined_features\":\n",
        "        steps.append(CombinedEnhancementAndFreq(homo_params=homo_params, log_params=log_params))\n",
        "    elif enhancement == \"none\":\n",
        "        steps.append(transforms.ToTensor())\n",
        "    return transforms.Compose(steps)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b8a38d7b"
      },
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# sample image\n",
        "image_path = \"/content/drive/MyDrive/Colab Notebooks/data/ECE253/82e90dbb-4b07-4f1f-b9d6-dfaead6cc602.png\"\n",
        "\n",
        "img_pil = Image.open(image_path).convert(\"RGB\")\n",
        "\n",
        "freq_magnitude = extract_frequency_features(img_pil)\n",
        "\n",
        "freq_magnitude_norm = (freq_magnitude - freq_magnitude.min()) / (freq_magnitude.max() - freq_magnitude.min() + 1e-6)\n",
        "freq_pil = Image.fromarray((freq_magnitude_norm * 255).astype(np.uint8))\n",
        "\n",
        "directory, filename = os.path.split(image_path)\n",
        "name, ext = os.path.splitext(filename)\n",
        "output_path = os.path.join(directory, f\"{name}_freq{ext}\")\n",
        "\n",
        "freq_pil.save(output_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ZxlzvUPTbyB",
        "outputId": "9e945c68-0663-4bd1-ff9e-b28a163e7bda"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Defined training_config dictionary.\n"
          ]
        }
      ],
      "source": [
        "training_config = {\n",
        "    \"train_dir\": \"/content/drive/MyDrive/Colab Notebooks/data/ECE253/lowlight/train\",\n",
        "    \"val_dir\": \"/content/drive/MyDrive/Colab Notebooks/data/ECE253/lowlight/validation\",\n",
        "    \"test_dir\": \"/content/drive/MyDrive/Colab Notebooks/data/ECE253/lowlight/test\",\n",
        "    \"img_size\": 64,\n",
        "    \"batch_size\": 128,\n",
        "    \"epochs\": 6,\n",
        "    \"lr\": 3e-4,\n",
        "    \"weight_decay\": 1e-4,\n",
        "    \"seed\": 42,\n",
        "    \"out_model\": \"/content/drive/MyDrive/Colab Notebooks/data/ECE253/best_resnet18_combined_features.pth\",\n",
        "    \"out_report\": \"/content/drive/MyDrive/Colab Notebooks/data/ECE253/test_results_combined_features.txt\",\n",
        "    \"keep_classes\": \"beach,buildings,forest,harbor,freeway\",\n",
        "    \"enhancement\": \"combined_features\",\n",
        "    \"homo_params\": {\"sigma\": 30.0, \"gamma_l\": 0.7, \"gamma_h\": 1.5},\n",
        "    \"log_params\": {\"c\": 1.0},\n",
        "    \"in_channels\": 4\n",
        "}\n",
        "print(\"Defined training_config dictionary.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4PXssVGjTe95",
        "outputId": "fd50944e-cda4-4b34-ae12-de284940fa18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<>:246: SyntaxWarning: invalid escape sequence '\\ '\n",
            "<>:246: SyntaxWarning: invalid escape sequence '\\ '\n",
            "/tmp/ipython-input-1066203315.py:246: SyntaxWarning: invalid escape sequence '\\ '\n",
            "  print(f\"\\ results saved to: {training_config['out_report']}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cpu\n",
            "Number of classes: 5\n",
            "Training samples: 1750\n",
            "Validation samples: 500\n",
            "Test samples: 250\n",
            "\n",
            "Starting training for 6 epochs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/6 [train]: 100%|██████████| 14/14 [01:10<00:00,  5.01s/it]\n",
            "Epoch 1/6 [val]: 100%|██████████| 4/4 [00:08<00:00,  2.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1: train_loss=0.9348  train_acc=0.7240  val_acc=0.3340\n",
            "  -> New best model saved to: /content/drive/MyDrive/Colab Notebooks/data/ECE253/best_resnet18_combined_features.pth (val_acc=0.3340)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2/6 [train]: 100%|██████████| 14/14 [01:10<00:00,  5.05s/it]\n",
            "Epoch 2/6 [val]: 100%|██████████| 4/4 [00:10<00:00,  2.72s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2: train_loss=0.1743  train_acc=0.9457  val_acc=0.3100\n",
            "  -> Val acc did not improve. Patience: 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3/6 [train]: 100%|██████████| 14/14 [01:09<00:00,  4.94s/it]\n",
            "Epoch 3/6 [val]: 100%|██████████| 4/4 [00:10<00:00,  2.55s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3: train_loss=0.0687  train_acc=0.9749  val_acc=0.6560\n",
            "  -> New best model saved to: /content/drive/MyDrive/Colab Notebooks/data/ECE253/best_resnet18_combined_features.pth (val_acc=0.6560)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4/6 [train]: 100%|██████████| 14/14 [01:12<00:00,  5.21s/it]\n",
            "Epoch 4/6 [val]: 100%|██████████| 4/4 [00:09<00:00,  2.49s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4: train_loss=0.0325  train_acc=0.9886  val_acc=0.8780\n",
            "  -> New best model saved to: /content/drive/MyDrive/Colab Notebooks/data/ECE253/best_resnet18_combined_features.pth (val_acc=0.8780)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5/6 [train]: 100%|██████████| 14/14 [01:12<00:00,  5.17s/it]\n",
            "Epoch 5/6 [val]: 100%|██████████| 4/4 [00:09<00:00,  2.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5: train_loss=0.0174  train_acc=0.9954  val_acc=0.9340\n",
            "  -> New best model saved to: /content/drive/MyDrive/Colab Notebooks/data/ECE253/best_resnet18_combined_features.pth (val_acc=0.9340)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 6/6 [train]: 100%|██████████| 14/14 [01:12<00:00,  5.16s/it]\n",
            "Epoch 6/6 [val]: 100%|██████████| 4/4 [00:09<00:00,  2.37s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6: train_loss=0.0063  train_acc=0.9977  val_acc=0.9440\n",
            "  -> New best model saved to: /content/drive/MyDrive/Colab Notebooks/data/ECE253/best_resnet18_combined_features.pth (val_acc=0.9440)\n",
            "\n",
            "Loading best model for final evaluation...\n",
            "\n",
            "Evaluating on validation set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Validating: 100%|██████████| 4/4 [00:12<00:00,  3.01s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== FINAL  RESULTS ====\n",
            "  Acc      = 0.9440\n",
            "  F1(macro)= 0.9441\n",
            "  AUC(OVR) = 0.9960\n",
            "\\ results saved to: /content/drive/MyDrive/Colab Notebooks/data/ECE253/test_results_combined_features.txt\n",
            "Best model saved to:   /content/drive/MyDrive/Colab Notebooks/data/ECE253/best_resnet18_combined_features.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "from pathlib import Path\n",
        "import sys\n",
        "import contextlib\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.cuda import amp\n",
        "\n",
        "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "def set_seed(seed: int = 42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def subset_imagefolder(dataset, keep_class_names):\n",
        "\n",
        "    orig_classes = list(dataset.classes)\n",
        "    new_classes = list(keep_class_names)\n",
        "    new_class_to_idx = {c: i for i, c in enumerate(new_classes)}\n",
        "\n",
        "    new_samples = []\n",
        "    new_targets = []\n",
        "\n",
        "    for path, old_label in dataset.samples:\n",
        "        cls_name = orig_classes[old_label]\n",
        "        if cls_name in new_class_to_idx:\n",
        "            new_label = new_class_to_idx[cls_name]\n",
        "            new_samples.append((path, new_label))\n",
        "            new_targets.append(new_label)\n",
        "\n",
        "    dataset.samples = new_samples\n",
        "    dataset.targets = new_targets\n",
        "    dataset.classes = new_classes\n",
        "    dataset.class_to_idx = new_class_to_idx\n",
        "\n",
        "    return dataset\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "set_seed(training_config[\"seed\"])\n",
        "IMG_SIZE = training_config[\"img_size\"]\n",
        "\n",
        "tf_train = build_eval_transform(\n",
        "    img_size=IMG_SIZE,\n",
        "    enhancement=training_config[\"enhancement\"],\n",
        "    homo_params=training_config.get(\"homo_params\"),\n",
        "    log_params=training_config.get(\"log_params\"),\n",
        "    in_channels=training_config[\"in_channels\"],\n",
        ")\n",
        "tf_eval = build_eval_transform(\n",
        "    img_size=IMG_SIZE,\n",
        "    enhancement=training_config[\"enhancement\"],\n",
        "    homo_params=training_config.get(\"homo_params\"),\n",
        "    log_params=training_config.get(\"log_params\"),\n",
        "    in_channels=training_config[\"in_channels\"],\n",
        ")\n",
        "\n",
        "train_ds = datasets.ImageFolder(training_config[\"train_dir\"], transform=tf_train)\n",
        "val_ds   = datasets.ImageFolder(training_config[\"val_dir\"],   transform=tf_eval)\n",
        "test_ds  = datasets.ImageFolder(training_config[\"test_dir\"],  transform=tf_eval)\n",
        "\n",
        "keep_cls_list = [c.strip() for c in training_config[\"keep_classes\"].split(\",\") if c.strip()]\n",
        "\n",
        "train_ds = subset_imagefolder(train_ds, keep_cls_list)\n",
        "val_ds   = subset_imagefolder(val_ds,   keep_cls_list)\n",
        "test_ds  = subset_imagefolder(test_ds,  keep_cls_list)\n",
        "\n",
        "num_classes = len(train_ds.classes)\n",
        "\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "print(f\"Training samples: {len(train_ds.samples)}\")\n",
        "print(f\"Validation samples: {len(val_ds.samples)}\")\n",
        "print(f\"Test samples: {len(test_ds.samples)}\")\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds,\n",
        "    batch_size=training_config[\"batch_size\"],\n",
        "    shuffle=True,\n",
        "    num_workers=0,\n",
        "    pin_memory=False,\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_ds,\n",
        "    batch_size=training_config[\"batch_size\"],\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=False,\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_ds,\n",
        "    batch_size=training_config[\"batch_size\"],\n",
        "    shuffle=False,\n",
        "    num_workers=0,\n",
        "    pin_memory=False,\n",
        ")\n",
        "\n",
        "model = build_resnet18(\n",
        "    num_classes=num_classes,\n",
        "    pretrained=True,\n",
        "    dropout=0.0,\n",
        "    freeze_backbone=False,\n",
        "    in_channels=training_config[\"in_channels\"],\n",
        ").to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=training_config[\"lr\"], weight_decay=training_config[\"weight_decay\"])\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5)\n",
        "\n",
        "EPOCHS = training_config[\"epochs\"]\n",
        "best_val_acc = 0.0\n",
        "epochs_no_improve = 0\n",
        "patience = 10\n",
        "\n",
        "use_amp = True if torch.cuda.is_available() else False\n",
        "scaler = amp.GradScaler() if use_amp else None\n",
        "\n",
        "print(f\"\\nStarting training for {EPOCHS} epochs...\")\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    model.train()\n",
        "    loss_sum = 0.0\n",
        "    y_true_train, y_pred_train = [], []\n",
        "\n",
        "    for imgs, labels in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS} [train]\"):\n",
        "        imgs = imgs.to(device, non_blocking=True)\n",
        "        labels = labels.to(device, non_blocking=True)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        with amp.autocast() if use_amp else contextlib.nullcontext():\n",
        "            logits = model(imgs)\n",
        "            loss = criterion(logits, labels)\n",
        "\n",
        "        if use_amp and scaler is not None:\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "        else:\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        loss_sum += loss.item()\n",
        "        y_pred_train += logits.argmax(1).detach().cpu().tolist()\n",
        "        y_true_train += labels.detach().cpu().tolist()\n",
        "\n",
        "    train_loss = loss_sum / len(train_loader)\n",
        "    train_acc = accuracy_score(y_true_train, y_pred_train)\n",
        "\n",
        "    model.eval()\n",
        "    val_true, val_pred = [], []\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels in tqdm(val_loader, desc=f\"Epoch {epoch}/{EPOCHS} [val]\"):\n",
        "            imgs = imgs.to(device, non_blocking=True)\n",
        "            with amp.autocast() if use_amp else contextlib.nullcontext():\n",
        "                logits = model(imgs)\n",
        "            preds = logits.argmax(1)\n",
        "\n",
        "            val_pred += preds.cpu().tolist()\n",
        "            val_true += labels.cpu().tolist()\n",
        "\n",
        "    val_acc = accuracy_score(val_true, val_pred)\n",
        "    scheduler.step(val_acc)\n",
        "\n",
        "    print(f\"Epoch {epoch}: train_loss={train_loss:.4f}  \" \\\n",
        "          f\"train_acc={train_acc:.4f}  val_acc={val_acc:.4f}\")\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        save_checkpoint(model, training_config[\"out_model\"])\n",
        "        epochs_no_improve = 0\n",
        "        print(f\"  -> New best model saved to: {training_config['out_model']} (val_acc={best_val_acc:.4f})\")\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        print(f\"  -> Val acc did not improve. Patience: {epochs_no_improve}/{patience}\")\n",
        "        if epochs_no_improve > patience:\n",
        "            print(f\"  -> Early stopping triggered after {patience} epochs without improvement.\")\n",
        "            break\n",
        "\n",
        "print(\"\\nLoading best model for final evaluation...\")\n",
        "best_model = build_resnet18(\n",
        "    num_classes=num_classes,\n",
        "    pretrained=False,\n",
        "    dropout=0.0,\n",
        "    freeze_backbone=False,\n",
        "    in_channels=training_config[\"in_channels\"],\n",
        ").to(device)\n",
        "\n",
        "load_checkpoint(best_model, training_config[\"out_model\"], map_location=device, expected_in_channels=training_config[\"in_channels\"])\n",
        "best_model.eval()\n",
        "\n",
        "y_true, y_pred, y_prob_rows = [], [], []\n",
        "\n",
        "print(\"\\nEvaluating on validation set...\")\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in tqdm(val_loader, desc=\"Validating\"):\n",
        "        imgs = imgs.to(device, non_blocking=True)\n",
        "        with amp.autocast() if use_amp else contextlib.nullcontext():\n",
        "            logits = best_model(imgs)\n",
        "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "        preds = logits.argmax(1).cpu().tolist()\n",
        "\n",
        "        y_true += labels.tolist()\n",
        "        y_pred += preds\n",
        "        y_prob_rows += probs.tolist()\n",
        "\n",
        "y_prob = np.array(y_prob_rows)\n",
        "\n",
        "row_sums = y_prob.sum(axis=1, keepdims=True)\n",
        "y_prob = np.divide(y_prob, row_sums, out=np.zeros_like(y_prob), where=row_sums != 0)\n",
        "\n",
        "\n",
        "acc = accuracy_score(y_true, y_pred)\n",
        "f1  = f1_score(y_true, y_pred, average='macro')\n",
        "auc = roc_auc_score(y_true, y_prob, multi_class='ovr')\n",
        "\n",
        "print(f\"\\n===== FINAL  RESULTS ====\")\n",
        "print(f\"  Acc      = {acc:.4f}\")\n",
        "print(f\"  F1(macro)= {f1:.4f}\")\n",
        "print(f\"  AUC(OVR) = {auc:.4f}\")\n",
        "\n",
        "with open(training_config[\"out_report\"], \"w\") as f:\n",
        "    f.write(\" results (best model based on val_acc) for combined features\\n\")\n",
        "    f.write(f\"Accuracy      : {acc:.6f}\\n\")\n",
        "    f.write(f\"F1 (macro)    : {f1:.6f}\\n\")\n",
        "    f.write(f\"AUC (OVR)     : {auc:.6f}\\n\")\n",
        "    f.write(f\"Best val_acc  : {best_val_acc:.6f}\\n\")\n",
        "    f.write(f\"Num classes   : {num_classes}\\n\")\n",
        "    f.write(f\"Used classes  : {train_ds.classes}\\n\")\n",
        "    f.write(f\"Train dir     : {training_config['train_dir']}\\n\")\n",
        "    f.write(f\"Val dir       : {training_config['val_dir']}\\n\")\n",
        "    f.write(f\"Test dir      : {training_config['test_dir']}\\n\")\n",
        "    f.write(f\"Enhancement   : {training_config['enhancement']}\\n\")\n",
        "    f.write(f\"In channels   : {training_config['in_channels']}\\n\")\n",
        "\n",
        "print(f\"\\n results saved to: {training_config['out_report']}\")\n",
        "print(f\"Best model saved to:   {training_config['out_model']}\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b6400bf",
        "outputId": "0c5391fc-0e4d-45cf-fb6c-6a888ac957f4"
      },
      "source": [
        "print(\"\\nLoading best model for final test evaluation...\")\n",
        "\n",
        "# Rebuild the model architecture\n",
        "best_model = build_resnet18(\n",
        "    num_classes=num_classes,\n",
        "    pretrained=False,\n",
        "    dropout=0.0,\n",
        "    freeze_backbone=False,\n",
        "    in_channels=training_config[\"in_channels\"],\n",
        ").to(device)\n",
        "\n",
        "# Load the best weights from the saved checkpoint\n",
        "load_checkpoint(best_model, training_config[\"out_model\"], map_location=device, expected_in_channels=training_config[\"in_channels\"])\n",
        "\n",
        "# Set the model to evaluation mode\n",
        "best_model.eval()\n",
        "\n",
        "y_true_test, y_pred_test, y_prob_rows_test = [], [], []\n",
        "\n",
        "print(\"\\nEvaluating on test set...\")\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in tqdm(test_loader, desc=\"Testing\"):\n",
        "        imgs = imgs.to(device, non_blocking=True)\n",
        "        with amp.autocast() if use_amp else contextlib.nullcontext():\n",
        "            logits = best_model(imgs)\n",
        "        probs = torch.softmax(logits, dim=1).cpu().numpy()\n",
        "        preds = logits.argmax(1).cpu().tolist()\n",
        "\n",
        "        y_true_test += labels.tolist()\n",
        "        y_pred_test += preds\n",
        "        y_prob_rows_test += probs.tolist()\n",
        "\n",
        "y_prob_test = np.array(y_prob_rows_test)\n",
        "\n",
        "row_sums_test = y_prob_test.sum(axis=1, keepdims=True)\n",
        "y_prob_test = np.divide(y_prob_test, row_sums_test, out=np.zeros_like(y_prob_test), where=row_sums_test != 0)\n",
        "\n",
        "\n",
        "acc_test = accuracy_score(y_true_test, y_pred_test)\n",
        "f1_test  = f1_score(y_true_test, y_pred_test, average='macro')\n",
        "auc_test = roc_auc_score(y_true_test, y_prob_test, multi_class='ovr')\n",
        "\n",
        "print(f\"\\n===== FINAL TEST RESULTS ====\")\n",
        "print(f\"  Acc      = {acc_test:.4f}\")\n",
        "print(f\"  F1(macro)= {f1_test:.4f}\")\n",
        "print(f\"  AUC(OVR) = {auc_test:.4f}\")\n",
        "\n",
        "\n",
        "with open(training_config[\"out_report\"], \"w\") as f:\n",
        "    f.write(\"Test results (best model based on val_acc) for combined features\\n\")\n",
        "    f.write(f\"Accuracy      : {acc_test:.6f}\\n\")\n",
        "    f.write(f\"F1 (macro)    : {f1_test:.6f}\\n\")\n",
        "    f.write(f\"AUC (OVR)     : {auc_test:.6f}\\n\")\n",
        "    f.write(f\"Best val_acc  : {best_val_acc:.6f}\\n\") # This is still the best val_acc from training\n",
        "    f.write(f\"Num classes   : {num_classes}\\n\")\n",
        "    f.write(f\"Used classes  : {train_ds.classes}\\n\")\n",
        "    f.write(f\"Train dir     : {training_config['train_dir']}\\n\")\n",
        "    f.write(f\"Val dir       : {training_config['val_dir']}\\n\")\n",
        "    f.write(f\"Test dir      : {training_config['test_dir']}\\n\")\n",
        "    f.write(f\"Enhancement   : {training_config['enhancement']}\\n\")\n",
        "    f.write(f\"In channels   : {training_config['in_channels']}\\n\")\n",
        "\n",
        "print(f\"\\nTest results saved to: {training_config['out_report']}\")\n",
        "print(f\"Best model saved to:   {training_config['out_model']}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Loading best model for final test evaluation...\n",
            "\n",
            "Evaluating on test set...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Testing: 100%|██████████| 2/2 [01:31<00:00, 45.59s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "===== FINAL TEST RESULTS ====\n",
            "  Acc      = 0.9280\n",
            "  F1(macro)= 0.9277\n",
            "  AUC(OVR) = 0.9945\n",
            "\n",
            "Test results saved to: /content/drive/MyDrive/Colab Notebooks/data/ECE253/test_results_combined_features.txt\n",
            "Best model saved to:   /content/drive/MyDrive/Colab Notebooks/data/ECE253/best_resnet18_combined_features.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1c_zHhmeVCw90jKcBufYDIjVxkaZobHKU",
      "authorship_tag": "ABX9TyPlr34VFcS2YwCxzYUXXnmo"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}